{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distances and Localised Regression (old, not important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tosig_pytorch import EsigPyTorch\n",
    "from esig import tosig\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# to plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors.ball_tree import BallTree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(sig, k, width, depth):\n",
    "    if not isinstance(k, int):\n",
    "        raise TypeError('k must be an integer')\n",
    "    if k<0:\n",
    "        raise NameError('projection level must be non-negative')\n",
    "    if k==0:\n",
    "        return np.array([1.])\n",
    "    if k > depth:\n",
    "        return np.zeros(width**k)\n",
    "    if isinstance(sig, torch.DoubleTensor):\n",
    "        sig = sig.numpy()\n",
    "    k1 = sum([width**i for i in range(k)])\n",
    "    k2 = sum([width**i for i in range(k+1)])\n",
    "    return sig[k1:k2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2(tensor):\n",
    "    return np.sqrt(sum([i**2 for i in tensor.flatten()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_distance(sig_1, sig_2, width, depth):\n",
    "    sig_diff = sig_1 - sig_2\n",
    "    projection_norms = [L2(projection(sig_diff, k, width, depth)) for k in range(depth+1)]\n",
    "    projection_norms[0] = 0.\n",
    "    return max(projection_norms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homogeneous Distance from Exercises 7.37 - 7.38 p. 146 in Friz-Victoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(sigtensor, width, depth):\n",
    "    projection_norms = [(math.factorial(k) * L2(\n",
    "                                                projection(\n",
    "                                                            pyt.tensor_log(sigtensor, depth)[1:], \n",
    "                                                            k, \n",
    "                                                            width, \n",
    "                                                            depth\n",
    "                                                           )\n",
    "                                               )\n",
    "                         )**(1./k)\n",
    "                        for k in range(1, depth+1)\n",
    "                       ]\n",
    "    return (math.factorial(depth)**(-1./depth))*max(projection_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hom_distance(stream_lhs, stream_rhs, width, depth):\n",
    "    stream_lhs_inverse = torch.from_numpy(np.flip(stream_lhs.numpy(), axis=0).copy())\n",
    "    sig_tensor_lhs_inverse = pyt.stream2sigtensor(stream_lhs_inverse, depth)\n",
    "    sig_tensor_rhs = pyt.stream2sigtensor(stream_rhs, depth)\n",
    "    prod = pyt.tensor_multiply(sig_tensor_lhs_inverse, sig_tensor_rhs, depth)\n",
    "    ans = norm(prod, width, depth)\n",
    "    if ans < 1e-07:\n",
    "        return 0.\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check non-negativity, symmetry and tringular inequality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyt = EsigPyTorch()\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    width = np.random.randint(2, 8)\n",
    "    depth = np.random.randint(2, 8)\n",
    "\n",
    "    print('Example {}: width = {} --- depth = {}'.format(i, width, depth))\n",
    "    \n",
    "    stream1 = pyt.brownian(100, width)\n",
    "    stream2 = pyt.brownian(100, width)\n",
    "    stream3 = pyt.brownian(100, width)\n",
    "    \n",
    "    s = time.time()\n",
    "    sigs1 = pyt.stream2sig(stream1, depth)\n",
    "    sigs2 = pyt.stream2sig(stream2, depth)\n",
    "    sigs3 = pyt.stream2sig(stream3, depth)\n",
    "    t = time.time()\n",
    "    \n",
    "    print('sig_avg_time : {} secs'.format((t-s)/3.))\n",
    "    \n",
    "    s = time.time()\n",
    "    a = projection_distance(sigs1, sigs2, width, depth)\n",
    "    a_sym = projection_distance(sigs2, sigs1, width, depth)\n",
    "    b = projection_distance(sigs1, sigs3, width, depth)\n",
    "    c = projection_distance(sigs2, sigs3, width, depth)\n",
    "    t = time.time()\n",
    "    \n",
    "    print('dist_avg_time : {} secs \\n'.format((t-s)/4.))\n",
    "    \n",
    "    if not a >= 0.:\n",
    "        print('Non-negativity not satisfied')\n",
    "    if not a == a_sym:\n",
    "        print('Symmetry not satisfied')\n",
    "    if not a + b >= c:\n",
    "        print('Triangular Inequality not satisfied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyt = EsigPyTorch()\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    width = np.random.randint(2, 8)\n",
    "    depth = np.random.randint(2, 8)\n",
    "\n",
    "    print('Example {}: width = {} --- depth = {}'.format(i, width, depth))\n",
    "    \n",
    "    stream1 = pyt.brownian(100, width)\n",
    "    stream2 = pyt.brownian(100, width)\n",
    "    stream3 = pyt.brownian(100, width)\n",
    "    \n",
    "    s = time.time()\n",
    "    a = hom_distance(stream1, stream2, width, depth)\n",
    "    a_sym = hom_distance(stream2, stream1, width, depth)\n",
    "    b = hom_distance(stream1, stream3, width, depth)\n",
    "    c = hom_distance(stream2, stream3, width, depth)\n",
    "    t = time.time()\n",
    "    \n",
    "    print('dist_avg_time : {} secs \\n'.format((t-s)/4.))\n",
    "    \n",
    "    if not a >= 0.:\n",
    "        print('Non-negativity not satisfied')\n",
    "    if not np.abs(a-a_sym)<1e-7:\n",
    "        print('Symmetry not satisfied: dist(a,b) = {} --- dist(b,a) = {}'.format(a, a_sym))\n",
    "    if not a + b >= c:\n",
    "        print('Triangular Inequality not satisfied')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit pathwise-prediction and subsequent classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load streams\n",
    "with open('input.pickle', 'rb') as handle:\n",
    "    X = pickle.load(handle, encoding='latin1')\n",
    "\n",
    "# load corresponding digit (optional)\n",
    "with open('output.pickle', 'rb') as handle:\n",
    "    y = pickle.load(handle, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a few examples\n",
    "for j in range(1, 5):\n",
    "    plt.plot(np.array([i[0] for i in X[j]]), np.array([i[1] for i in X[j]]))\n",
    "    plt.title('this is supposed to be a {}'.format(y[j]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('We have {} images in total \\n'.format(len(X)))\n",
    "print ('The first few digits have shapes: {}'.format([X[0].shape, \n",
    "                                                      X[1].shape,\n",
    "                                                      X[2].shape]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localised Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_index = 1000\n",
    "data = list(zip(X[:stop_index], y[:stop_index]))\n",
    "random.shuffle(data)\n",
    "X, y = zip(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only retaining the first 80% of the information in the test set\n",
    "percentage_to_retain = 0.8\n",
    "X_input = [i[:int(percentage_to_retain*float(len(i))),:] for i in X]\n",
    "X_missing_part = [i[int(percentage_to_retain*float(len(i))):,:] for i in X]\n",
    "X_output = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(.95*len(X))\n",
    "X_input_train = X_input[:split]\n",
    "X_input_test = X_input[split:]\n",
    "X_output_train = X_output[:split]\n",
    "X_output_test = X_output[split:]\n",
    "\n",
    "# y_available = np.array(y[:split], np.newaxis).astype(float)\n",
    "# y_test = np.array(y[split:], np.newaxis).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalisedRegression:\n",
    "    \n",
    "    def __init__(self, X_input_train, X_output_train, k_nn=5, width=2, depth=2):  \n",
    "        self.X_input_train = X_input_train\n",
    "        self.X_output_train = X_output_train\n",
    "        self.k_nn = k_nn\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        # compute signatures of training data streams\n",
    "        self.X_sigs_input, self.X_sigs_output = self.compute_signatures()\n",
    "        self.pyt = EsigPyTorch()\n",
    "        \n",
    "    def compute_signatures(self):\n",
    "        X_sigs_input = np.array([tosig.stream2sig(item, self.depth) for item in X_input_train])\n",
    "        X_sigs_output = np.array([tosig.stream2sig(item, self.depth) for item in X_output_train])\n",
    "        return X_sigs_input, X_sigs_output\n",
    "    \n",
    "    def mydist(self, x, y):\n",
    "        return projection_distance(x, y, width=self.width, depth=self.depth)\n",
    "\n",
    "    def train(self, x=None, y=None):\n",
    "        pass\n",
    "    \n",
    "    def getKey(self, item):\n",
    "        return item[2]\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \n",
    "        # calculate S(x)^-1\n",
    "        x_inverse = torch.from_numpy(np.flip(x, axis=0).copy())\n",
    "        sig_tensor_x_inverse = pyt.stream2sigtensor(x_inverse, self.depth)\n",
    "        \n",
    "        # pre-multiply training data by S(x)^-1\n",
    "        prod_in = np.array([pyt.tensor_multiply(sig_tensor_x_inverse, torch.tensor(np.insert(t, 0, 2.)), self.depth)[1:].numpy() for t in self.X_sigs_input])\n",
    "        \n",
    "        # calculate path signature\n",
    "        x_sig = tosig.stream2sig(x, self.depth)\n",
    "        \n",
    "        # compute distances from x_sig to premultiplied training data signatures\n",
    "        distances = [(x_in, x_out, self.mydist(x_sig, x_in)) for x_in, x_out in zip(prod_in, self.X_sigs_output)]\n",
    "        \n",
    "        # pick k-NN\n",
    "        l = sorted(distances, key=self.getKey)\n",
    "        X_in_local = [i[0] for i in l[:self.k_nn]]\n",
    "        X_out_local = [i[1] for i in l[:self.k_nn]]\n",
    "        \n",
    "        # run linear regression locally on the selected k-NN\n",
    "        lin_reg = LinearRegression()\n",
    "        lin_reg.fit(X_in_local, X_out_local)\n",
    "        \n",
    "        return lin_reg.predict(np.array([x_sig]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalisedRegressionHomogeneous:\n",
    "    \n",
    "    def __init__(self, X_input_train, X_output_train, k_nn=5, width=2, depth=2):  \n",
    "        self.X_input_train = X_input_train\n",
    "        self.X_output_train = X_output_train\n",
    "        self.k_nn = k_nn\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.pyt = EsigPyTorch()\n",
    "        # input signatures are calculated on the fly\n",
    "        self.signatures_output = self.compute_signatures_output()\n",
    "    \n",
    "    def norm(self, sigtensor, width, depth):\n",
    "        projection_norms = [(math.factorial(k) * L2(\n",
    "                                                    projection(\n",
    "                                                                self.pyt.tensor_log(sigtensor, depth)[1:], \n",
    "                                                                k, \n",
    "                                                                width, \n",
    "                                                                depth\n",
    "                                                               )\n",
    "                                                   )\n",
    "                             )**(1./k)\n",
    "                            for k in range(1, depth+1)\n",
    "                           ]\n",
    "        return (math.factorial(depth)**(-1./depth))*max(projection_norms)\n",
    "\n",
    "    def hom_distance(self, stream_lhs, stream_rhs, width, depth):\n",
    "        stream_lhs_inverse = torch.from_numpy(np.flip(stream_lhs, axis=0).copy())\n",
    "        sig_tensor_lhs_inverse = self.pyt.stream2sigtensor(stream_lhs_inverse, depth)\n",
    "        sig_tensor_rhs = self.pyt.stream2sigtensor(stream_rhs, depth)    \n",
    "        \n",
    "        self.sig_in = sig_tensor_rhs[1:]\n",
    "        \n",
    "        prod = self.pyt.tensor_multiply(sig_tensor_lhs_inverse, sig_tensor_rhs, depth)\n",
    "        ans = self.norm(prod, self.width, self.depth)\n",
    "        if ans < 1e-07:\n",
    "            return 0., sig_tensor_rhs\n",
    "        return ans\n",
    "\n",
    "    def compute_signatures_output(self):\n",
    "        return [self.pyt.stream2sig(torch.tensor(item), self.depth) for item in self.X_output_train]\n",
    "        \n",
    "    def train(self, x=None, y=None):\n",
    "        pass\n",
    "    \n",
    "    def getKey(self, item):\n",
    "        return item[0]\n",
    "    \n",
    "    def predict(self, x):\n",
    "\n",
    "        # compute distances from x to training data streams\n",
    "        distances = [(self.hom_distance(x, torch.tensor(x_in), self.width, self.depth), self.sig_in,\n",
    "                      x_out) for x_in, x_out in zip(self.X_input_train, self.signatures_output)]\n",
    "        \n",
    "        # pick k-NN\n",
    "        l = sorted(distances, key=self.getKey)\n",
    "        X_in_local = [i[1].numpy() for i in l[:self.k_nn]]\n",
    "        X_out_local = [i[2].numpy() for i in l[:self.k_nn]]\n",
    "        \n",
    "        # run linear regression locally on the selected k-NN\n",
    "        lin_reg = LinearRegression()\n",
    "        lin_reg.fit(X_in_local, X_out_local)\n",
    "        \n",
    "        return lin_reg.predict(np.array([tosig.stream2sig(x, self.depth)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_predictions = 5\n",
    "\n",
    "for k in [7, 10, 15, 20, 50]:\n",
    "    for d in [2, 3, 4, 5]:\n",
    "        print('\\n \\n Predictions for k_nn = {}, depth = {}'.format(k, d))\n",
    "        model = LocalisedRegressionHomogeneous(X_input_train, X_output_train, k_nn=k, depth=d)\n",
    "        predicted_sigs = [model.predict(ex) for ex in X_input_test[:n_predictions]]\n",
    "        real_paths = [p for p in X_output_test[:n_predictions]]\n",
    "        increments = [p[0][1:3] for p in predicted_sigs]\n",
    "        starting_points = [sp[0] for sp in real_paths]\n",
    "        predicted_paths = [np.append(ex, np.array([sp+inc]), axis=0) for ex, sp, inc in zip(X_input_test[:n_predictions],\n",
    "                                                                                            starting_points,\n",
    "                                                                                            increments)]\n",
    "        for item in range(n_predictions):\n",
    "            plt.plot(np.array([i[0] for i in predicted_paths[item]]), np.array([i[1] for i in predicted_paths[item]]), marker='o')\n",
    "            plt.plot(np.array([i[0] for i in real_paths[item]]), np.array([i[1] for i in real_paths[item]]))\n",
    "            plt.title('prediction #{} with k_nn={}, depth={}'.format(item, k, d))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
