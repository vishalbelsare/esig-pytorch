{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iisignature\n",
    "import torch\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigFn(Function):\n",
    "    def __init__(self, m):\n",
    "        super(SigFn, self).__init__()\n",
    "        self.m = m\n",
    "    def forward(self, X):\n",
    "        result=iisignature.sig(X.detach().numpy(), self.m)\n",
    "        self.save_for_backward(X)\n",
    "        return torch.FloatTensor(result)\n",
    "    def backward(self, grad_output):\n",
    "        (X,) = self.saved_tensors\n",
    "        result = iisignature.sigbackprop(grad_output.numpy(), X.detach().numpy(),self.m)\n",
    "        return torch.FloatTensor(result)\n",
    "\n",
    "class LogSigFn(Function):\n",
    "    def __init__(self, s, method):\n",
    "        super(LogSigFn, self).__init__()\n",
    "        self.s = s\n",
    "        self.method = method\n",
    "    def forward(self,X):\n",
    "        result=iisignature.logsig(X.detach().numpy(), self.s, self.method)\n",
    "        self.save_for_backward(X)\n",
    "        return torch.FloatTensor(result)\n",
    "    def backward(self, grad_output):\n",
    "        (X,) = self.saved_tensors\n",
    "        g = grad_output.numpy()\n",
    "        result = iisignature.logsigbackprop(g, X.detach().numpy(),self.s,self.method)\n",
    "        return torch.FloatTensor(result)\n",
    "\n",
    "def Sig(X,m):\n",
    "    return SigFn(m)(X)\n",
    "\n",
    "def LogSig(X,s,method=\"\"):\n",
    "    return LogSigFn(s,method)(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tosig_pytorch import EsigPyTorch\n",
    "sig_PT = EsigPyTorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dim = 2\n",
    "depth = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $X: [0, 1] \\rightarrow R^2$ be a piecewise linear path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input streams\n",
    "X = torch.randn((10, 2), dtype=torch.double, requires_grad=True)\n",
    "X_jer = torch.tensor(X.data, dtype=torch.float, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute signatures up to level 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our sigs\n",
    "my_sigs = sig_PT.stream2sig(X, 3)\n",
    "\n",
    "# Jeremy's sigs\n",
    "j_sigs = Sig(X_jer, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is our signature: \n",
      " tensor([  1.7940,  -2.4478,   1.6093,  -7.1627,   2.7712,   2.9959,   0.9624,\n",
      "        -12.5614,  12.2727,   7.3248,  -3.6505,   2.8834,  -4.8334,  -2.4445],\n",
      "       dtype=torch.float64) \n",
      " \n",
      "\n",
      "This is Jeremy s signature: \n",
      " tensor([  1.7940,  -2.4478,   1.6093,  -7.1627,   2.7712,   2.9959,   0.9624,\n",
      "        -12.5614,  12.2727,   7.3248,  -3.6505,   2.8834,  -4.8334,  -2.4445]) \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('This is our signature: \\n {} \\n \\n'.format(my_sigs.data[1:]))\n",
    "print('This is Jeremy s signature: \\n {} \\n \\n'.format(j_sigs.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' () (1) (2) (1,1) (1,2) (2,1) (2,2) (1,1,1) (1,1,2) (1,2,1) (1,2,2) (2,1,1) (2,1,2) (2,2,1) (2,2,2)'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_PT.sigkeys(path_dim, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to calculate the derivative of the $k^{th}$ entry of the signature with respect to the input path. This will correspond to the derivative obtained by perturbing the input path pointwise by white noise, evaluated at the input path.\n",
    "\n",
    "For example, let's compute\n",
    "\n",
    "$$\\frac{dS^{(2, 2)}}{dX} = (\\frac{dS^{(2, 2)}}{dX_{i,j}})_{i,j}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 7\n",
    "k_jer = 6\n",
    "\n",
    "inp = torch.zeros(my_sigs.size(), dtype=torch.double)\n",
    "inp[k] = 1.\n",
    "\n",
    "inp_jer = torch.zeros(j_sigs.size())\n",
    "inp_jer[k_jer] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our gradients with backprop\n",
    "my_sigs.backward(inp)\n",
    "\n",
    "# Jeremy's gradients with backprop\n",
    "j_sigs.backward(inp_jer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " This is our gradient with respect to the input: \n",
      " tensor([[-1.6093,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [-0.0000,  0.0000],\n",
      "        [-0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [-0.0000,  0.0000],\n",
      "        [ 1.6093,  0.0000]], dtype=torch.float64) \n",
      " \n",
      "\n",
      "\n",
      " This is Jeremy s gradient with respect to the input: \n",
      " tensor([[-1.6093,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 1.6093,  0.0000]]) \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n This is our gradient with respect to the input: \\n {} \\n \\n'.format(X.grad))\n",
    "print('\\n This is Jeremy s gradient with respect to the input: \\n {} \\n \\n'.format(X_jer.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
